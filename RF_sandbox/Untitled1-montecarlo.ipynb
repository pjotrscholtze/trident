{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "harmful-practice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dm-acme in ./venv/lib/python3.8/site-packages (0.2.0)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.8/site-packages (from dm-acme) (1.19.5)\n",
      "Requirement already satisfied: dm-tree in ./venv/lib/python3.8/site-packages (from dm-acme) (0.1.5)\n",
      "Requirement already satisfied: dm-env in ./venv/lib/python3.8/site-packages (from dm-acme) (1.3)\n",
      "Requirement already satisfied: pillow in ./venv/lib/python3.8/site-packages (from dm-acme) (7.2.0)\n",
      "Requirement already satisfied: absl-py in ./venv/lib/python3.8/site-packages (from dm-acme) (0.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.8/site-packages (from dm-tree->dm-acme) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.0 is available.\n",
      "You should consider upgrading via the '/home/pjotr/projects/poc/tutorials/datascience/venv/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n",
      "zsh:1: no matches found: dm-acme[reverb]\n",
      "zsh:1: no matches found: dm-acme[tf]\n",
      "Requirement already satisfied: gym in ./venv/lib/python3.8/site-packages (0.10.11)\n",
      "Requirement already satisfied: numpy>=1.10.4 in ./venv/lib/python3.8/site-packages (from gym) (1.19.5)\n",
      "Requirement already satisfied: pyglet>=1.2.0 in ./venv/lib/python3.8/site-packages (from gym) (1.3.2)\n",
      "Requirement already satisfied: requests>=2.0 in ./venv/lib/python3.8/site-packages (from gym) (2.25.1)\n",
      "Requirement already satisfied: six in ./venv/lib/python3.8/site-packages (from gym) (1.15.0)\n",
      "Requirement already satisfied: scipy in ./venv/lib/python3.8/site-packages (from gym) (1.6.0)\n",
      "Requirement already satisfied: future in ./venv/lib/python3.8/site-packages (from pyglet>=1.2.0->gym) (0.18.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.8/site-packages (from requests>=2.0->gym) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./venv/lib/python3.8/site-packages (from requests>=2.0->gym) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./venv/lib/python3.8/site-packages (from requests>=2.0->gym) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./venv/lib/python3.8/site-packages (from requests>=2.0->gym) (1.26.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.0 is available.\n",
      "You should consider upgrading via the '/home/pjotr/projects/poc/tutorials/datascience/venv/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install dm-acme\n",
    "!pip install dm-acme[reverb]\n",
    "!pip install dm-acme[tf]\n",
    "!pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "opposite-luxury",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_library = 'gym'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "elementary-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "from acme import environment_loop\n",
    "from acme import specs\n",
    "from acme import wrappers\n",
    "from acme.agents.tf import d4pg\n",
    "from acme.agents.tf import ddpg\n",
    "from acme.tf import networks\n",
    "from acme.tf import utils as tf2_utils\n",
    "from acme.utils import loggers\n",
    "import numpy as np\n",
    "import sonnet as snt\n",
    "import gym\n",
    "import time\n",
    "\n",
    "\n",
    "environment = gym.make('MountainCarContinuous-v0')\n",
    "environment = wrappers.GymWrapper(environment)  # To dm_env interface.\n",
    "\n",
    "# Make sure the environment outputs single-precision floats.\n",
    "environment = wrappers.SinglePrecisionWrapper(environment)\n",
    "\n",
    "# Grab the spec of the environment.\n",
    "environment_spec = specs.make_environment_spec(environment)\n",
    "\n",
    "#@title Build agent networks\n",
    "\n",
    "# Get total number of action dimensions from action spec.\n",
    "num_dimensions = np.prod(environment_spec.actions.shape, dtype=int)\n",
    "\n",
    "# Create the shared observation network; here simply a state-less operation.\n",
    "observation_network = tf2_utils.batch_concat\n",
    "\n",
    "# Create the deterministic policy network.\n",
    "policy_network = snt.Sequential([\n",
    "    networks.LayerNormMLP((256, 256, 256), activate_final=True),\n",
    "    networks.NearZeroInitializedLinear(num_dimensions),\n",
    "    networks.TanhToSpec(environment_spec.actions),\n",
    "])\n",
    "\n",
    "# Create the distributional critic network.\n",
    "critic_network = snt.Sequential([\n",
    "    # The multiplexer concatenates the observations/actions.\n",
    "    networks.CriticMultiplexer(),\n",
    "#     networks.LayerNormMLP((512, 512, 256), activate_final=True),\n",
    "    networks.LayerNormMLP((512, 512, 1), activate_final=True),\n",
    "#     networks.DiscreteValuedHead(vmin=-150., vmax=150., num_atoms=51),\n",
    "])\n",
    "\n",
    "# Create a logger for the agent and environment loop.\n",
    "agent_logger = loggers.TerminalLogger(label='agent', time_delta=10.)\n",
    "env_loop_logger = loggers.TerminalLogger(label='env_loop', time_delta=10.)\n",
    "\n",
    "# Create the D4PG agent.\n",
    "agent = ddpg.DDPG(\n",
    "    environment_spec=environment_spec,\n",
    "    policy_network=policy_network,\n",
    "    critic_network=critic_network,\n",
    "    observation_network=observation_network,\n",
    "    sigma=1.0,\n",
    "    logger=agent_logger,\n",
    "    checkpoint=False\n",
    ")\n",
    "\n",
    "# Create an loop connecting this agent to the environment created above.\n",
    "env_loop = environment_loop.EnvironmentLoop(\n",
    "    environment, agent, logger=env_loop_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "likely-buddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Writer-object deleted without calling .close explicitly.\n",
      "WARNING:absl:Writer-object deleted without calling .close explicitly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Agent] Critic Loss = 0.038 | Policy Loss = 0.000 | Steps = 1 | Walltime = 0\n",
      "[Env Loop] Episode Length = 999 | Episode Return = -51.893978118896484 | Episodes = 2 | Steps = 1998 | Steps Per Second = 60.058\n",
      "[Agent] Critic Loss = 0.025 | Policy Loss = 0.000 | Steps = 432 | Walltime = 10.009\n",
      "[Env Loop] Episode Length = 999 | Episode Return = -52.25935745239258 | Episodes = 6 | Steps = 5994 | Steps Per Second = 341.244\n",
      "[Agent] Critic Loss = 0.030 | Policy Loss = 0.000 | Steps = 841 | Walltime = 20.015\n",
      "[Env Loop] Episode Length = 999 | Episode Return = -51.88341522216797 | Episodes = 10 | Steps = 9990 | Steps Per Second = 333.790\n"
     ]
    }
   ],
   "source": [
    "env_loop.run(num_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "widespread-channels",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3a95e0057d57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0menvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0125\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "timestep = environment.reset()\n",
    "action = agent.select_action(timestep.observation)\n",
    "\n",
    "while not timestep.last():\n",
    "    environment.render()\n",
    "    environment.step(action)\n",
    "    time.sleep(0.0125)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
